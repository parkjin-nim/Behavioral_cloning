{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "lines = []\n",
    "with open(\"../data/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "        \n",
    "images = []\n",
    "measurements = []\n",
    "\n",
    "for line in lines[1:]:\n",
    "    for i in range(3):\n",
    "        source_path = line[i]\n",
    "        file_name = source_path.split('/')[-1]\n",
    "        current_path = '../data/IMG/'+file_name\n",
    "        image = cv2.imread(current_path)\n",
    "        images.append(image)\n",
    "\n",
    "        measurement = float(line[3])\n",
    "        measurements.append(measurement)\n",
    "    \n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images, augmented_measurements = [],[]\n",
    "for image, measurement in zip(images, measurements):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "    augmented_images.append(cv2.flip(image,1))\n",
    "    augmented_measurements.append(measurement*-1)\n",
    "    \n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# keras ==2.4.3\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Flatten(input_shape=(160,320,3)))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "#In Keras, lambda layers can be used to create arbitrary functions that operate on each image as it passes through the layer.\n",
    "#In this project, a lambda layer is a convenient way to parallelize image normalization. \n",
    "#The lambda layer will also ensure that the model will normalize input images when making predictions in drive.py.\n",
    "\n",
    "model.add(Convolution2D(6,5,5,activation='relu'))\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0)), input_shape=(160,320,3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(6,5,5,activation='relu'))\n",
    "model.add(MaxPooling2D())          \n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(80))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    epochs=5)\n",
    "\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(history.history['loss'], label='Trainining Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating Your Network\n",
    "In order to validate your network, you'll want to compare model performance on the training set and a validation set. The validation set should contain image and steering data that was not used for training. A rule of thumb could be to use 80% of your data for training and 20% for validation or 70% and 30%. Be sure to randomly shuffle the data before splitting into training and validation sets.\n",
    "\n",
    "If model predictions are poor on both the training and validation set (for example, mean squared error is high on both), then this is evidence of underfitting. Possible solutions could be to\n",
    "\n",
    "* increase the number of epochs\n",
    "* add more convolutions to the network.\n",
    "\n",
    "When the model predicts well on the training set but poorly on the validation set (for example, low mean squared error for training set, high mean squared error for validation set), this is evidence of overfitting. If the model is overfitting, a few ideas could be to\n",
    "\n",
    "* use dropout or pooling layers\n",
    "* use fewer convolution or fewer fully connected layers\n",
    "* collect more data or further augment the data set\n",
    "Ideally, the model will make good predictions on both the training and validation sets. The implication is that when the network sees an image, it can successfully predict what angle was being driven at that moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "img =  cv2.imread(\"../data2/IMG/center_2020_09_06_22_31_26_703.jpg\")\n",
    "print(img.shape)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program pipelines using model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# keras ==2.4.3\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "\n",
    "def process_images(path_csv, path_IMG):\n",
    "    lines = []\n",
    "    #with open(\"../data/driving_log.csv\") as csvfile:\n",
    "    with open(path_csv) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            lines.append(line)\n",
    "\n",
    "    print(\"Reading images from \", path_csv)\n",
    "    car_images, steering_angles = [], []\n",
    "    for line in lines[1:]:   \n",
    "        steering_center = float(line[3])\n",
    "        row = [source_path.split('/')[-1] for source_path in line[0:3]]\n",
    "\n",
    "        # create adjusted steering measurements for the side camera images\n",
    "        correction = 0.2 # this is a parameter to tune\n",
    "        steering_left = steering_center + correction\n",
    "        steering_right = steering_center - correction\n",
    "\n",
    "        # read in images from center, left and right cameras\n",
    "        #path = \"../data/IMG/\" # fill in the path to your training IMG directory\n",
    "        img_center = np.asarray(Image.open(path_IMG + row[0]))\n",
    "        img_left = np.asarray(Image.open(path_IMG + row[1]))\n",
    "        img_right = np.asarray(Image.open(path_IMG + row[2]))\n",
    "\n",
    "        # add images and angles to data set\n",
    "        car_images.extend([img_center, img_left, img_right])\n",
    "        steering_angles.extend([steering_center, steering_left, steering_right])\n",
    "    \n",
    "    return car_images, steering_angles\n",
    "\n",
    "def flipping_images(car_images, steering_angles):\n",
    "    print(\"Augmenting images...\")\n",
    "    augmented_images, augmented_measurements = [],[]\n",
    "    for image, measurement in zip(car_images, steering_angles):\n",
    "        #augmented_images.append(image)\n",
    "        #augmented_measurements.append(measurement)\n",
    "        augmented_images.append(cv2.flip(image,1))\n",
    "        augmented_measurements.append(measurement*-1.0)\n",
    "    \n",
    "    return augmented_images, augmented_measurements\n",
    "\n",
    "augmented_images, augmented_measurements = process_images(\"../data/driving_log.csv\", \"../data/IMG/\")\n",
    "flip_images, flip_measurements = flipping_images(augmented_images, augmented_measurements)\n",
    "augmented_images+= flip_images\n",
    "augmented_measurements+= flip_measurements\n",
    "\n",
    "\n",
    "trk2_aug_images, trk2_aug_measurements = process_images(\"../data2/driving_log.csv\", \"../data2/IMG/\")\n",
    "augmented_images+=trk2_aug_images\n",
    "augmented_measurements+=trk2_aug_measurements\n",
    "\n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurements)\n",
    "print(\"Traing data shape is, \",X_train.shape, y_train.shape)\n",
    "\n",
    "\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# input(3x160x320) is cropped to 3x65x320\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "\n",
    "\n",
    "model.add(Convolution2D(24,5,5,subsample=(2,2),activation='relu'))\n",
    "model.add(Convolution2D(36,5,5,subsample=(2,2),activation='relu'))\n",
    "model.add(Convolution2D(48,5,5,subsample=(2,2),activation='relu'))\n",
    "model.add(Convolution2D(64,3,3,activation='relu'))\n",
    "model.add(Convolution2D(64,3,3,activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    epochs=10)\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "plt.plot(history.history['loss'], label='Trainining Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovery Laps\n",
    "If you drive and record normal laps around the track, even if you record a lot of them, it might not be enough to train your model to drive properly.\n",
    "\n",
    "Here’s the problem: if your training data is all focused on driving down the middle of the road, your model won’t ever learn what to do if it gets off to the side of the road. And probably when you run your model to predict steering measurements, things won’t go perfectly and the car will wander off to the side of the road at some point.\n",
    "\n",
    "So you need to teach the car what to do when it’s off on the side of the road.\n",
    "\n",
    "One approach might be to constantly wander off to the side of the road and then steer back to the middle.\n",
    "\n",
    "A better approach is to only record data when the car is driving from the side of the road back toward the center line.\n",
    "\n",
    "So as the human driver, you’re still weaving back and forth between the middle of the road and the shoulder, but you need to turn off data recording when you weave out to the side, and turn it back on when you steer back to the middle.\n",
    "\n",
    "### Driving Counter-Clockwise\n",
    "Track one has a left turn bias. If you only drive around the first track in a clock-wise direction, the data will be biased towards left turns. One way to combat the bias is to turn the car around and record counter-clockwise laps around the track. Driving counter-clockwise is also like giving the model a new track to learn from, so the model will generalize better.\n",
    "\n",
    "### Using Both Tracks\n",
    "If you end up using data from only track one, the convolutional neural network could essentially memorize the track. Consider using data from both track one and track two to make a more generalized model.\n",
    "\n",
    "### Collecting Enough Data\n",
    "How do you know when you have collected enough data? Machine learning involves trying out ideas and testing them to see if they work. If the model is over or underfitting, then try to figure out why and adjust accordingly.\n",
    "\n",
    "Since this model outputs a single continuous numeric value, one appropriate error metric would be mean squared error. If the mean squared error is high on both a training and validation set, the model is underfitting. If the mean squared error is low on a training set but high on a validation set, the model is overfitting. Collecting more data can help improve a model when the model is overfitting.\n",
    "\n",
    "What if the model has a low mean squared error on both the training and validation sets, but the car is falling off the track?\n",
    "\n",
    "Try to figure out the cases where the vehicle is falling off the track. Does it occur only on turns? Then maybe it's important to collect more turning data. The vehicle's driving behavior is only as good as the behavior of the driver who provided the data.\n",
    "\n",
    "Here are some general guidelines for data collection:\n",
    "\n",
    "* two or three laps of center lane driving\n",
    "* one lap of recovery driving from the sides\n",
    "* one lap focusing on driving smoothly around curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Use Generators\n",
    "The images captured in the car simulator are much larger than the images encountered in the Traffic Sign Classifier Project, a size of 160 x 320 x 3 compared to 32 x 32 x 3. Storing 10,000 traffic sign images would take about 30 MB but storing 10,000 simulator images would take over 1.5 GB. That's a lot of memory! Not to mention that preprocessing data can change data types from an int to a float, which can increase the size of the data by a factor of 4.\n",
    "\n",
    "Generators can be a great way to work with large amounts of data. **Instead of storing the preprocessed data in memory all at once, using a generator you can pull pieces of the data and process them on the fly only when you need them, which is much more memory-efficient.**\n",
    "\n",
    "A generator is like a coroutine, a process that can run separately from another main routine, which makes it a useful Python function. Instead of using return, the generator uses yield, which still returns the desired output values but saves the current values of all the generator's variables. **When the generator is called a second time it re-starts right after the yield statement, with all its variables set to the same values as before.**\n",
    "\n",
    "Below is a short quiz using a generator. This generator appends a new Fibonacci number to its list every time it is called. To pass, simply modify the generator's yield so it returns a list instead of 1. The result will be we can get the first 10 Fibonacci numbers simply by calling our generator 10 times. If we need to go do something else besides generate Fibonacci numbers for a while we can do that and then always just call the generator again whenever we need more Fibonacci numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci():\n",
    "    numbers_list = []\n",
    "    while 1:\n",
    "        if(len(numbers_list) < 2):\n",
    "            numbers_list.append(1)\n",
    "        else:\n",
    "            numbers_list.append(numbers_list[-1] + numbers_list[-2])\n",
    "        yield numbers_list # change this line so it yields its list instead of 1\n",
    "\n",
    "our_generator = fibonacci()\n",
    "my_output = []\n",
    "\n",
    "for i in range(10):\n",
    "    my_output = (next(our_generator))\n",
    "    \n",
    "print(my_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how you could use a generator to load data and preprocess it on the fly, in batch size portions to feed into your Behavioral Cloning model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "samples = []\n",
    "with open('./driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = './IMG/'+batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# Set our batch size\n",
    "batch_size=32\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n",
    "ch, row, col = 3, 80, 320  # Trimmed image format\n",
    "\n",
    "model = Sequential()\n",
    "# Preprocess incoming data, centered around zero with small standard deviation \n",
    "model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "        input_shape=(ch, row, col),\n",
    "        output_shape=(ch, row, col)))\n",
    "model.add(... finish defining the rest of your model architecture here ...)\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history_object = model.fit_generator(train_generator, \n",
    "            steps_per_epoch=ceil(len(train_samples)/batch_size), \n",
    "            validation_data=validation_generator, \n",
    "            validation_steps=ceil(len(validation_samples)/batch_size), \n",
    "            epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputting Training and Validation Loss Metrics\n",
    "In Keras, the model.fit() and model.fit_generator() methods have a verbose parameter that tells Keras to output loss metrics as the model trains. The verbose parameter can optionally be set to verbose = 1 or verbose = 2.\n",
    "\n",
    "Setting model.fit(verbose = 1) will\n",
    "\n",
    "* output a progress bar in the terminal as the model trains.\n",
    "* output the loss metric on the training set as the model trains.\n",
    "* output the loss on the training and validation sets after each epoch.\n",
    "\n",
    "With model.fit(verbose = 2), Keras will only output the loss on the training set and validation set after each epoch.\n",
    "\n",
    "Model History Object\n",
    "When calling model.fit() or model.fit_generator(), Keras outputs a history object that contains the training and validation loss for each epoch. Here is an example of how you can use the history object to visualize the loss:\n",
    "\n",
    "\n",
    "The following code shows how to use the model.fit() history object to produce the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch =\n",
    "    len(train_samples), validation_data = \n",
    "    validation_generator,\n",
    "    nb_val_samples = len(validation_samples), \n",
    "    nb_epoch=5, verbose=1)\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator 변환은 매 epoch마다 반복되면 오히려 처리가 느려지는 것 아닌가? \n",
    "### 아니다.Memogy문제라서 3G이상 데이터인 경우 generator batch가 아니면 run시키기 어렵다.\n",
    "### 매 epoch마다 io가 되는 것도 아닌거같다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program pipelines using model.fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 size: 8340\n",
      "data2 size: 14301\n",
      "11440 2861\n",
      "The number of total samples is... 67923\n",
      "Building model...\n",
      "Training starts..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinpark/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:105: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "/Users/jinpark/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:106: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "/Users/jinpark/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:107: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "/Users/jinpark/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "/Users/jinpark/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:109: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "358/358 [==============================] - 696s 2s/step - loss: 0.0196 - val_loss: 0.0164\n",
      "Epoch 2/10\n",
      "358/358 [==============================] - 542s 2s/step - loss: 0.0162 - val_loss: 0.0144\n",
      "Epoch 3/10\n",
      "358/358 [==============================] - 1163s 3s/step - loss: 0.0151 - val_loss: 0.0138\n",
      "Epoch 4/10\n",
      "358/358 [==============================] - 556s 2s/step - loss: 0.0144 - val_loss: 0.0126\n",
      "Epoch 5/10\n",
      "358/358 [==============================] - 548s 2s/step - loss: 0.0136 - val_loss: 0.0125\n",
      "Epoch 6/10\n",
      "358/358 [==============================] - 571s 2s/step - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 7/10\n",
      "358/358 [==============================] - 565s 2s/step - loss: 0.0123 - val_loss: 0.0111\n",
      "Epoch 8/10\n",
      "358/358 [==============================] - 595s 2s/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 9/10\n",
      "358/358 [==============================] - 612s 2s/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 10/10\n",
      "358/358 [==============================] - 573s 2s/step - loss: 0.0100 - val_loss: 0.0097\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "# keras ==2.4.3\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "samples = []\n",
    "with open('../comb_data/driving_log1.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader, None)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "data1_size = len(samples)\n",
    "print(\"data1 size:\",len(samples))\n",
    "\n",
    "with open('../comb_data/driving_log2.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    counter = 0\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "        counter +=1\n",
    "\n",
    "data2_size = counter\n",
    "print(\"data2 size:\",len(samples))\n",
    "\n",
    "shuffle(samples)\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "print(len(train_samples), len(validation_samples))\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            #print(\"batch samples from:\",offset,\" to: \", offset+batch_size, \" len: \", len(batch_samples))\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                steering_center = float(line[3])\n",
    "                row = [source_path.split('/')[-1] for source_path in batch_sample[0:3]]\n",
    "\n",
    "                # create adjusted steering measurements for the side camera images\n",
    "                correction = 0.2 # this is a parameter to tune\n",
    "                steering_left = steering_center + correction\n",
    "                steering_right = steering_center - correction\n",
    "\n",
    "                # read in images from center, left and right cameras\n",
    "                path = \"../comb_data/IMG/\" # fill in the path to your training IMG directory\n",
    "                img_center = np.asarray(Image.open(path + row[0]))\n",
    "                img_left = np.asarray(Image.open(path + row[1]))\n",
    "                img_right = np.asarray(Image.open(path + row[2]))\n",
    "\n",
    "                # add images and angles to data set\n",
    "                images.extend([img_center, img_left, img_right])\n",
    "                angles.extend([steering_center, steering_left, steering_right])\n",
    "                \n",
    "                augmented_images, augmented_measurements = [],[]\n",
    "                for image, measurement in zip([img_center, img_left, img_right], \n",
    "                                              [steering_center, steering_left, steering_right]):\n",
    "                    augmented_images.append(cv2.flip(image,1))\n",
    "                    augmented_measurements.append(measurement*-1.0)\n",
    "\n",
    "                images += augmented_images\n",
    "                angles += augmented_measurements\n",
    "                #print(len(images), len(angles))\n",
    "            \n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            #print(\"Adding \",len(X_train))\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# Set our batch size\n",
    "batch_size=32\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "print(\"The number of total samples is...\", data1_size*3*2+data2_size*3)\n",
    "train_generator = generator(train_samples, batch_size=batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = Sequential()\n",
    "# Preprocess incoming data, centered around zero with small standard deviation \n",
    "# input(3x160x320) is cropped to 3x65x320\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "\n",
    "\n",
    "model.add(Convolution2D(24,5,5,subsample=(2,2),activation='relu'))\n",
    "model.add(Convolution2D(36,5,5,subsample=(2,2),activation='relu'))\n",
    "model.add(Convolution2D(48,5,5,subsample=(2,2),activation='relu'))\n",
    "model.add(Convolution2D(64,3,3,activation='relu'))\n",
    "model.add(Convolution2D(64,3,3,activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "print(\"Training starts..\")\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history_object = model.fit_generator(train_generator, \n",
    "            steps_per_epoch=np.ceil(len(train_samples)/batch_size), \n",
    "            validation_data=validation_generator, \n",
    "            validation_steps=np.ceil(len(validation_samples)/batch_size), \n",
    "            epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd8VGX2+PHPSSMQOgklBEiQIDWEDlKkg6i4KCq2NYq66iqWXb+r7rqu7Lq6Pxv2CrJ2QcXFgnQUAemdUAIEEkog9JqQ5Pz+uDc4REgGmGQmyXm/XvNi5t7n3jmThJw8z3PveURVMcYYY85XkL8DMMYYU7pZIjHGGHNBLJEYY4y5IJZIjDHGXBBLJMYYYy6IJRJjjDEXxBKJKXYiMk5E/uVl21QR6VfcMRkQkdkicoe/4yiMiKiINPF3HKZwlkiMMcZcEEskxpQBIhISSO99rvH4M35z4SyRGODUkNIjIrJSRI6KyBgRqSMik0XksIhMF5EaHu2HiMgaETngDpE099jXVkSWusd9DoQXeK8rRGS5e+w8EUnwMsZxIvKGG9MREZkrInVFZLSI7BeRdSLS1qN9tIh8KSJ7RGSLiIz02NdJROa7MewUkddEJMxjv4rI3SKy0T336yIiZ4mrk4gsFpFDIpIhIi967LtFRLaKyF4R+avn0F3BIT8R6SUi6R6vHxWRTe7Xca2IDPXYl+R+/pdEZB/wD3f77SKS7MY8RUQaeRzT3/0aHRSR14Azfh63bZDH++8VkfEiUtPdF+t+fUaIyDZg5pm2uW0L+zlJFZG/iMhK4GhRyUREqonIB+73c6uI/E1Egtx9TUTkR/ezZbo/d4jjJRHZ7e5bKSKtCnsfcx5U1R72AEgFfgHqAPWB3cBSoC1QAecXw5Nu26bAUaA/EAr8H5AChLmPrcBD7r5hwEngX+6x7dxzdwaCgVvd967gEUe/s8Q4DsgE2uMkp5nAFuD37rn+Bcxy2wYBS4C/uzE1BjYDA9397YEuQAgQCyQDD3q8lwLfAtWBhsAeYNBZ4poP3OI+rwx0cZ+3AI4APd2v4YtATv7ncz/PvzzO0wtI93h9LRDtfpbr3a95PXdfknuu+93PUBH4nft9aO5u+xswz20fCRxyvx+h7vcnB7jjLJ/pQffnIcaN/W3gU3dfrPv1+QCIcN/7TNvO+nPi8b1eDjQAKp4lDgWauM8/AP4HVHHfbwMwwt33KfBX92sVDnR3tw90fw6q4yTO5vlfQ3v48PeHvwOwR2A83P/UN3m8/hJ40+P1/cDX7vMngPEe+4KA7e4vwp7ADkA89s/j10TyJvDPAu+9HrjUI47CEsm7BWJK9njdGjjgPu8MbCtw/GPA+2c594PARI/Xmv/LyH09Hnj0LMf+BDwFRBbY/nfgM4/XEUA2XiaSM7zPcuAq93nSGT7f5PxfrB7fl2NAI5xk+4vHPgHSOXsiSQb6eryuh/MHQX7iVaCxx/4zbTvrz4nH9/r2In4uFWiC84dCFtDCY98fgNnu8w+Ad4CYAsf3wUk4XYAgf/8/K6sPG9oynjI8nh8/w+vK7vNonF4HAKqaB6Th9GSige3q/i92bfV43gj4kzvUcUBEDuD8RRrt4xgbAdEF3udxnB4XItJURL4VkV0icgj4N85f7Z52eTw/5nHugkbg/PW9TkQWicgV7vZonK8LAKp6FNjr5edERH7vMQR4AGhVIMa0Aoc0Al72aL8PJ2Hkf188Y9EzHF/wXBM9zpUM5OJ+/c7y/gW3FfZzUtg5ziSSX3u7+bZ6nOv/cD7rQnco7Xb3PWcCrwGvAxki8o6IVPXyPY2XLJGY87ED5xcN4IxD4ySD7cBOoH6B+YSGHs/TgKdVtbrHo5KqfurjGNOALQXep4qqDnb3vwmsA+JVtSpOkjnrnEFhVHWjqt4A1Ab+A3whIhE4X4sG+e1EpBJQy+PQo0Alj9d1Pdo2At4F7gNqqWp1YHWBGAuW7k4D/lDgM1dU1XlniEU8X59BGnBZgXOFq+r2Qt6/4LbCfk4KO8eZZOL0iBp5bGuYfy5V3aWqd6pqNE5P5Q1xLxtW1VdUtT3QEifhP+LlexovWSIx52M8cLmI9BWRUOBPOMMO83DmC3KAkSISIiJXA508jn0XuFtEOrsToREicrmIVPFxjAuBQ+5kbkURCRaRViLS0d1fBWfO4IiINAPuOd83EpGbRSTK/Yv7gLs5F/gCuEJEuoszkT+K0//PLQcGi0hNEamLM7yWLwLnl+we9z1uw+mRFOYt4DERaekeU01ErnX3fQe0FJGr3UntkXgkrrOc6+n8yXoRiRKRq4p4/4IK+zk5J6qa657vaRGp4sb1MPCRG9+1IhLjNt+P87XLFZGO7s9aKE7iPoHzvTE+ZInEnDNVXQ/cDLyK85filcCVqpqtqtnA1Thj+PtxJom/8jh2MXAnznDDfpzJ16RiiDHXjSsRZ0I+E3gPqOY2+TNwI3AYJ7l9fgFvNwhYIyJHgJeB4ap6QlXXAH8EPsHpEezHmZfI9yGwAmeuYKpnDKq6FngBJzFn4Mz/zC0sCFWdiNMj+swdrlsNXObuy8SZvH8WZ3gtvojzvQxMAqaKyGGciffORXwdCsZz1p+TczmPh/txksFm4Gecr+tYd19HYIH7PZgEPKCqW4CqON/f/ThDYXuB58/z/c1ZyOlD2caY4iQiqTgT3NP9HYsxvmI9EmOMMRfEEokxxpgLYkNbxhhjLkix9khEZJCIrBeRFBF59Az7K4jI5+7+BSIS627vLyJLRGSV+28fj2Pau9tTROSVApeZGmOMKWHF1iMRkWCcO0r741ypsgi4wb0aJb/NvUCCqt4tIsOBoap6vTj1kjJUdYdbF2eKqtZ3j1kIPIBzFcn3wCuqOrmwWCIjIzU2Ntb3H9IYY8qwJUuWZKpqVFHtirPiZicgRVU3A4jIZ8BVwFqPNlfhFpvDueb+NRERVV3m0WYNEC4iFYCaQFVVne+e8wOc+kKFJpLY2FgWL1584Z/IGGPKERHZWnSr4h3aqs/p5Q/SOb00wmltVDUHOMjpd/4CXAMsU9Ust73ndfhnOicAInKXOBVZF+/Zs+e8P4QxxpjCFWciOdPcRcFxtELbuHfo/gen5IG353Q2qr6jqh1UtUNUVJE9M2OMMeepOBNJOqfX8onBqb1zxjZu2YZqOIXmcMsdTAR+r6qbPNrHeBx/pnMaY4wpQcU5R7IIiBeROJzCasNxSlJ4moSzHsV8nHUSZqqqikh1nNpAj6nqqTIOqrpTnEV+ugALcEpjv1qMn8EY4yMnT54kPT2dEydO+DsUU0B4eDgxMTGEhoae1/HFlkhUNUdE7gOm4KwlMFZV14jIKGCxqk4CxgAfikgKTk9kuHv4fThrEDwhIk+42wao6m6c4nrjcBbOmUwRE+3GmMCQnp5OlSpViI2Nxa7aDxyqyt69e0lPTycuLu68zlEubkjs0KGD2lVbxvhXcnIyzZo1syQSgFSVdevW0bx589O2i8gSVe1Q1PFWIsUYU2IsiQSmC/2+WCI5i9w85fNF25i8aqe/QzHGmIBmieQsggQ+XrCNf09O5mRunr/DMcZcoAMHDvDGG2+c17GDBw/mwIEDhbb5+9//zvTpJb86wNdff83atWuLbliMLJGchYjwQN940vYdZ+Ky7UUfYIwJaIUlktzcwhdN/P7776levXqhbUaNGkW/fv3OO77zZYkkwPVpVpvW9avx2swU65UYU8o9+uijbNq0icTERB555BFmz55N7969ufHGG2ndujUAv/vd72jfvj0tW7bknXfeOXVsbGwsmZmZpKam0rx5c+68805atmzJgAEDOH78OABJSUl88cUXp9o/+eSTtGvXjtatW7Nu3ToA9uzZQ//+/WnXrh1/+MMfaNSoEZmZmafFmZubS1JSEq1ataJ169a89NJLAGzatIlBgwbRvn17evTowbp165g3bx6TJk3ikUceITExkU2bNuEPxXkfSaknIjzYL54R/13M18u2c22HBkUfZIwp0lPfrGHtjkM+PWeL6Ko8eWXLs+5/9tlnWb16NcuXLwdg9uzZLFy4kNWrV5+67HXs2LHUrFmT48eP07FjR6655hpq1Tq9atPGjRv59NNPeffdd7nuuuv48ssvufnmm3/zfpGRkSxdupQ33niD559/nvfee4+nnnqKPn368Nhjj/HDDz+clqzyLV++nO3bt7N69WqAU0Nqd911F2+99Rbx8fEsWLCAe++9l5kzZzJkyBCuuOIKhg0bdn5fOB+wRFKEU72SWSkMbVufkGDrxBlTVnTq1Om0eydeeeUVJk6cCEBaWhobN278TSKJi4sjMTERgPbt25OamnrGc1999dWn2nz11VcA/Pzzz6fOP2jQIGrUqPGb4xo3bszmzZu5//77ufzyyxkwYABHjhxh3rx5XHvttafaZWVlneen9j1LJEXInyu544PFfL18B8PaxxR9kDGmUIX1HEpSRETEqeezZ89m+vTpzJ8/n0qVKtGrV68z3oVfoUKFU8+Dg4NPDW2drV1wcDA5OTmAc79GUWrUqMGKFSuYMmUKr7/+OuPHj2f06NFUr179VG8q0Nif117o27w2repX5dWZG8mxuRJjSqUqVapw+PDhs+4/ePAgNWrUoFKlSqxbt45ffvnF5zF0796d8ePHAzB16lT279//mzaZmZnk5eVxzTXX8M9//pOlS5dStWpV4uLimDBhAuAkpBUrVnj1uUqCJRIvOL2Spmzde4z/LbcakcaURrVq1aJbt260atWKRx555Df7Bw0aRE5ODgkJCTzxxBN06dLF5zE8+eSTTJ06lXbt2jF58mTq1atHlSpVTmuzfft2evXqRWJiIklJSTzzzDMAfPzxx4wZM4Y2bdrQsmVL/ve//wEwfPhwnnvuOdq2beu3yXYrkeIlVeWKV3/maFYO0x++1OZKjDlHycnJvynBUd5kZWURHBxMSEgI8+fP55577gmY4aozfX+8LZFicyReyp8ruevDJUxasYOr29lciTHm3Gzbto3rrruOvLw8wsLCePfdd/0dkk9YIjkH/VvUoUW9qrw6M4UhbaKtV2KMOSfx8fEsW7as6IaljP0mPAciwgP94tmSeZRvVtpciTHGgCWSczagRR2a16vKqzNSyM0r+/NLxhhTFEsk5yh/rmRz5lG+WWG9EmOMsURyHga0qEOzulV4ZeZG65UYY8o9SyTnISjIqcG1ec9RvrW5EmPKrMqVKwOwY8eOs9ay6tWrF0XdXjB69GiOHTt26rU3Zel9LTU1lU8++aRYzm2J5DwNaFGXZnWr8PIM65UYU9ZFR0efqux7PgomEm/K0vuaJZIAFBTkzpVYr8SYUuEvf/nLaeuR/OMf/+CFF17gyJEj9O3b91TJ9/w7xj2lpqbSqlUrAI4fP87w4cNJSEjg+uuvP63W1j333EOHDh1o2bIlTz75JOAUgtyxYwe9e/emd+/ewK9l6QFefPFFWrVqRatWrRg9evSp9ztbuXpPEyZMoFWrVrRp04aePXsCThn6Rx55hI4dO5KQkMDbb78NOGX058yZQ2Ji4qnS9L5i95FcgIEt63JxnSq8MmMjVyREExxk61Eb45XJj8KuVb49Z93WcNmzZ909fPhwHnzwQe69914Axo8fzw8//EB4eDgTJ06katWqZGZm0qVLF4YMGXLWdczffPNNKlWqxMqVK1m5ciXt2rU7te/pp5+mZs2a5Obm0rdvX1auXMnIkSN58cUXmTVrFpGRkaeda8mSJbz//vssWLAAVaVz585ceuml1KhRw6ty9aNGjWLKlCnUr1//1FDZmDFjqFatGosWLSIrK4tu3boxYMAAnn32WZ5//nm+/fbb8/ryFsZ6JBcgKMi5r2TTnqN8Z2u7GxPQ2rZty+7du9mxYwcrVqygRo0aNGzYEFXl8ccfJyEhgX79+rF9+3YyMjLOep6ffvrp1C/0hIQEEhISTu0bP3487dq1o23btqxZs6bIlQt//vlnhg4dSkREBJUrV+bqq69mzpw5gHfl6rt160ZSUhLvvvvuqVUep06dygcffEBiYiKdO3dm7969bNy48Zy+VufKeiQXaJBHr+Ty1vWsV2KMNwrpORSnYcOG8cUXX7Br1y6GDx8OOMUQ9+zZw5IlSwgNDSU2NvaM5eM9nam3smXLFp5//nkWLVpEjRo1SEpKKvI8hdU69KZc/VtvvcWCBQv47rvvSExMZPny5agqr776KgMHDjyt7ezZswuN5UJYj+QCBQUJI/vGk7L7CN9br8SYgDZ8+HA+++wzvvjii1NXYR08eJDatWsTGhrKrFmz2Lp1a6Hn6NmzJx9//DEAq1evZuXKlQAcOnSIiIgIqlWrRkZGBpMnTz51zNlKvffs2ZOvv/6aY8eOcfToUSZOnEiPHj28/jybNm2ic+fOjBo1isjISNLS0hg4cCBvvvkmJ0+eBGDDhg0cPXq0WMvNW4/EBy5rVZemdSrzyoyNDLZeiTEBq2XLlhw+fJj69etTr149AG666SauvPJKOnToQGJiIs2aNSv0HPfccw+33XYbCQkJJCYm0qlTJwDatGlD27ZtadmyJY0bN6Zbt26njrnrrru47LLLqFevHrNmzTq1vV27diQlJZ06xx133EHbtm3PuupiQY888ggbN25EVenbty9t2rQhISGB1NRU2rVrh6oSFRXF119/TUJCAiEhIbRp04akpCQeeuihc/nSFcrKyPvItyt3cN8ny3j1hrZc2Sa6WN/LmNLIysgHtgspI29DWz4yuFU94ms7vZI8u6/EGFOOWCLxkfy5ko27j/D9apsrMcaUH5ZIfGhw63o0sV6JMWdVHobSS6ML/b5YIvGhYLdXsiHjCJNX7/J3OMYElPDwcPbu3WvJJMCoKnv37iU8PPy8z2FXbfnY5a3r8fL0DbwyYyOXtapLkF3BZQwAMTExpKens2fPHn+HYgoIDw8nJub8lw8v1kQiIoOAl4Fg4D1VfbbA/grAB0B7YC9wvaqmikgt4AugIzBOVe/zOOYG4HFAgR3AzaqaWZyf41zk90oe+Gw5P6zZxeDW9fwdkjEBITQ0lLi4OH+HYYpBsQ1tiUgw8DpwGdACuEFEWhRoNgLYr6pNgJeA/7jbTwBPAH8ucM4QnMTUW1UTgJXAfQSYKxKiuSgqwuZKjDHlQnHOkXQCUlR1s6pmA58BVxVocxXwX/f5F0BfERFVPaqqP+MkFE/iPiLEqVFQFadXElDyeyXrdh1myhqbKzHGlG3FmUjqA2ker9PdbWdso6o5wEGg1tlOqKongXuAVTgJpAUw5kxtReQuEVksIov9MSZ7RUI0jaMieNl6JcaYMq44E8mZZpkL/kb1ps2vjUVCcRJJWyAaZ2jrsTO1VdV3VLWDqnaIioryLmIfCg4SRvZxeiVT11qvxBhTdhVnIkkHGni8juG3w1Cn2rjzH9WAfYWcMxFAVTepcw3heOASXwXsa1e2iaZxZAQvz0ixXokxpswqzkSyCIgXkTgRCQOGA5MKtJkE3Oo+HwbM1MIvMt8OtBCR/C5GfyDZhzH7VHCQcH/fJiTvPMTUtWdf38AYY0qzYksk7pzHfcAUnF/241V1jYiMEpEhbrMxQC0RSQEeBh7NP15EUoEXgSQRSReRFqq6A3gK+ElEVuL0UP5dXJ/BF65McHolr8zYaDdiGWPKJKv+WwK+WprOw+NX8PYt7RnYsq7f4jDGmHNh1X8DyJA20cRFRvDydOuVGGPKHkskJSAkOIj7ejdh7c5DTLO5EmNMGVNkIhGRa0Wkivv8byLylYi0K/7QyparEqOJrVWJl22uxBhTxnjTI3lCVQ+LSHdgIM6d6G8Wb1hlT0hwEPf1iWfNjkNMT97t73CMMcZnvEkkue6/lwNvqur/gLDiC6ns+l1iNI1qVeLlGRusV2KMKTO8SSTbReRt4Drge7dir82tnIf8uZLV2w8xw3olxpgywpuEcB3OvSCDVPUAUBN4pFijKsOGtq3v9kpsrsQYUzZ4k0jqAd+p6kYR6QVcCyws1qjKsJDgIP7Yuwmrth9k5jrrlRhjSj9vEsmXQK6INMG5Ez0O+KRYoyrjhratT8Oa1isxxpQN3iSSPLfcydXAaFV9CKeXYs5TqDtXsjL9ILPWW6/EGFO6eZNITrrL2/4e+NbdFlp8IZUPQ9vVp0HNina3uzGm1PMmkdwGdAWeVtUtIhIHfFS8YZV9+b2SFekHmb2+5BfeMsYYXykykajqWpy101eJSCsgXVWfLfbIyoGr28UQU6Mio6fbfSXGmNLLmxIpvYCNwOvAG8AGEelZzHGVC6f1SjZYr8QYUzp5M7T1AjBAVS9V1Z44ZVJeKt6wyo9feyU2V2KMKZ28SSShqro+/4WqbsAm230mLMS5r2RF2gF+tF6JMaYU8iaRLBaRMSLSy328Cywp7sDKk2vaxVC/uvVKjDGlkzeJ5B5gDTASeABYC9xdnEGVN2EhQdzXpwnL0w7w08ZMf4djjDHnxJurtrJU9UVVvVpVh6rqS6qaVRLBlSe/9krsCi5jTOkScrYdIrIKOOtvNFVNKJaIyqn8uZLHJ65izsZMejaN8ndIxhjjlbMmEuCKEovCADCsfQyvz0ph9PQN9IiPRET8HZIxxhTprENbqrq1sEdJBllehIUEcW/vi1i67QA/p9hciTGmdLAFqgLMte0bEF0t3K7gMsaUGpZIAozTK2nCkq37mZuy19/hGGNMkQpNJCISLCLlt0Bj1hHIPlrib3tthxjqVQu3K7iMMaVCoYlEVXOBKBEJK6F4AkfuSXj/Mph4N+TllehbVwgJ5t7eTVi8dT/zNlmvxBgT2LwZ2koF5orIEyLycP6jmOPyv+BQSLgOkifBj/8p8be/znolxphSwptEsgNnQasgoIrHo+zreh8k3gQ/PgtrJpboW1cICebeXhexKHU/861XYowJYIXdRwKAqj4FICJVnJd6pNijChQicMVLsDcFJt4DNeIgOrHE3v66jg14fdYmRk/fSNeLatl9JcaYgOTNeiStRGQZsBpYIyJLRKRl8YcWIEIqwPUfQaVa8NmNcHhXib21M1dyEQtT9/Htyp0l9r7GGHMuvBnaegd4WFUbqWoj4E/Au8UbVoCpXBtu+BSO74fPboKTJ0rsra/r0IBmdatw/6fLeOCzZew5bGXOjDGBxZtEEqGqs/JfqOpsIMKbk4vIIBFZLyIpIvLoGfZXEJHP3f0LRCTW3V5LRGaJyBERea3AMWEi8o6IbBCRdSJyjTexXLB6CTD0bdi+GL4ZCSU0AR4eGszXf+zGA33jmbxqF31fmM0nC7aRl2cT8MaYwOBNItnsXrEV6z7+Bmwp6iARCcZZnvcyoAVwg4i0KNBsBLBfVZvgrLqYf3nUCeAJnLXiC/orsFtVm7rn/dGLz+AbLYZA77/Bys9h7ugSe9vw0GAe6t+UyQ/2oEV0VR6fuIpr357P+l2HSywGY4w5G28Sye1AFPCV+4gEbvPiuE5AiqpuVtVs4DPgqgJtrgL+6z7/AugrIqKqR1X1Z5yEcqZ4ngFQ1TxVLdmiVD3/DK2ugelPwbrvS/StL4qqzKd3duH5a9uwec8RLn9lDv/vh3Ucz84t0TiMMcZTkXe2A4+r6khVbec+HlTV/V6cuz6Q5vE63d12xjaqmgMcBGoVEk919+k/RWSpiEwQkTpnaXuXiCwWkcV79vhwCVsRuOp15+qtr+6EjDW+O7dXby8Max/DjD/14ndt6/PG7E0MHP2TLdNrjPEbb+5sb3+e5z7TtaoFB/a9aeMpBIgB5qpqO2A+8PyZGqrqO6raQVU7REX5eG2P0Iow/BMIqwyfDoejJV+pt2ZEGM9f24ZP7+xCSLBw69iF3P/pMnYfLrkLAYwxBrwb2lomIpNE5BYRuTr/4cVx6UADj9cxODc3nrGNiIQA1YB9hZxzL3AMyL87cALQzotYfK9qtJNMjuyG8b+HnGy/hNH1olpMfqAHD/VrypTVu+j7wo98vGCrTcYbY0qMN4mkJs4v8D7Ale7Dm0WvFgHxIhLn1uoaDkwq0GYScKv7fBgwUwupB+Lu+wbo5W7qi7OGvH/EtIchr8HWufD9n0rsSq6CKoQE80C/eH54sAet61fjrxNXM+yteazbdcgv8RhjyhcprI6TO0cyUlVfOq+TiwwGRgPBwFhVfVpERgGLVXWSiIQDHwJtcXoiw1V1s3tsKlAVCAMOAANUda2INHKPqQ7sAW5T1W2FxdGhQwddvHjx+XwE78wYBXNegEH/gS53F9/7eEFVmbhsO//6LplDx09yR4/GPNA3nophwX6NyxhT+ojIElXtUGS7ogoCisgsVe3ts8j8oNgTSV4efH4zbJgMN30BTfoW33t5af/RbJ6ZnMz4xenE1KjIP3/Xit4X1/Z3WMaYUsTbROLN0NY8EXlNRHqISLv8hw9iLDuCguDqd6B2C5hwG2Ru9HdE1IgI4/8Na8Nnd3WhQkgQt72/iD9+spTdh2wy3hjjW171SM6wWVW1T/GE5HvF3iPJd2AbvNMbwqvBnTOgYo3if08vZOXk8s6Pm3l1VgoVgoP4v8uacVOnhgQFWRFIY8zZ+WxoqywosUQCsHU+/PdKiO3uDHMFF1lgucRsyTzK375exdyUvbRtWJ1/D21N83pV/R2WMSZA+WxoS0TqiMgYEZnsvm4hIiN8EWSZ1KirU3p+8yyY+ld/R3OauMgIPhrRmZeub8PWvce44tWfeWZyMseyc/wdmjGmFPNmjmQcMAWIdl9vAB4sroDKhHa3OItiLXgLFr/v72hOIyIMbRvDjIcvZVi7GN7+cTMDXvqJWet2+zs0Y0wp5U0iiVTV8UAenCplYsWditJ/FDTpB9//GVJ/9nc0v1EjIoz/DEtg/B+6Eh4azG3jFvHHj5eSYZPxxphz5E0iOSoitXBLl4hIF5yaWKYwQcEwbCzUbAyf3wL7iiyY7Bed4mry/cge/HlAU6YlZ9DvhR/5cH4quXZnvDHGS94kkodx7kC/SETmAh8A9xdrVGVFeDW44TPQPPj0BjgRmHeah4UEcV+feKY+2JM2DarzxP/WcM2b81i7IzDjNcYEFq+u2nLrYF2MU2RxvaqeLO7AfKlEr9o6k82z4cOAhZS0AAAgAElEQVSrIb6/U58rKHDvMldV/rd8B//8di0Hjp9kRPc4HuwXT6WwwLn6zBhTMnx5QyKqmqOqa1R1dWlLIgGhcS+47D+w4QeY8ZS/oymUiPC7tvWZ8adLua5DDO/8tJn+L/7EzHUZ/g7NGBOgvEokxgc63QkdRsDcl2HFZ/6OpkjVK4XxzNUJTLi7K5XCgrl93GLu+WgJKbttVUZjzOnshsSSlHsSPhwKaQsg6Xto0NHfEXklOyePd+ds5pUZG8nKyaPXxVGM6B5H9yaRiNjd8caUVRd8Z3tR9bRUdel5xlbiAiaRABzbB+/2geyjcNcsqBbj74i8lnkki49/2caHv6SSeSSbZnWrcHv3OIa0iSY8NHDnfYwx58cXiSS/xlY40AFYgTPZngAsUNXuPoq12AVUIgHYsx7e6wc1YuH2HyAswt8RnZOsnFwmLd/BmJ+3sG7XYSIrh3Fzl0bc3KURkZUr+Ds8Y4yP+LKM/GfA06q6yn3dCvizqib5ItCSEHCJBGDjNPjkOmh2BVz7X6eCcCmjqszbtJf35mxm1vo9hIUEMTSxPiN6xNG0ThV/h2eMuUC+TCTLVTWxqG2BLCATCcC8V2Hq3+DSR6H3Y/6O5oKk7D7C2Llb+GppOidO5tEjPpIR3eO4tGmUzaMYU0r5MpF8ChwFPsK5u/1moLKq3uCLQEtCwCYSVfjfH2H5x3DtOGg51N8RXbD9R7P5ZOE2/jsvld2Hs4ivXZnbu8cxtG19m0cxppTxZSIJB+4BerqbfgLeVNVSU5QpYBMJQE6WU3Z+50pnviS61HT0CpWdk8e3K3fw3pwtrN15iJoRYdzcuSE3d21E7Srh/g7PGOMFn65HIiIVgYaqut4XwZW0gE4kAEd2O1dyaR7cOROq1PV3RD6jqvyyeR9jft7CjHUZhAYFMSQxmhHd42wtFGMCnC97JEOA54AwVY0TkURglKoO8U2oxS/gEwnArlUwZoCzXG/SdxBa9v5q35J5lPfnbmHC4nSOn8ylW5NajOgeR6+mtW21RmMCkC8TyRKgDzBbVdu621aqaoJPIi0BpSKRACR/A5/fDAnXw9C3oYxOUh84ls2nC9P477xUdh06QeOoCG7vFsc17WKoGGbzKMYECl/W2spRVSsbXxKaXwl9/gYrP4e5o/0dTbGpXimMe3pdxJy/9Obl4YlUrhDC375eTddnZ/DclHW2JooxpYw3JV1Xi8iNQLCIxAMjgXnFG1Y51uPPsDsZpj8FkRdDs8H+jqjYhAYHcVVifYa0iWbx1v28N2czb8zexDs/bebKhGhu7x5Hq/rV/B2mMaYI3gxtVQL+CgxwN00B/mVXbRWjk8fh/csgcyOMmAp1Wvo7ohKzde9R3p+byoTFaRzNzqVzXE3u6NGYvs1sHsWYkuaTORIRCQaeVdVHfBlcSSt1iQTg0A54pzeEhMGdsyAi0t8RlaiDx08yflEa4+alsv3AcWJrVeL27nEMax9ja6MYU0J8Odk+U1X7+CwyPyiViQQgfQmMGwz128MtXztJpZzJyc3jhzW7eG/OFpanHaBqeAg3dG7IrV1jia5e0d/hGVOm+TKRvADEAxNw7nAHQFW/utAgS0qpTSQAq76AL0dApVoQPwCaDoKL+kB4+bsHY8nW/Yz9eQuTV+9ERBjcuh4juseR2KC6v0MzpkzyZSJ5/wybVVVvP9/gSlqpTiQAG6bCqgmwcSqcOABBoRDbHS6+DJoOdKoIlyNp+47xwfxUPluYxuGsHNo3qsHt3eIY2LIOIcGlr/ilMYHKp3e2l3alPpHky81xFsXa8IPzyNzgbI9qDhcPgqaXQUyHgF4T3peOZOUwYXEa789NZdu+Y9SvXpGkS2K5rmMDqlUM9Xd4xpR6vq61NQJoibM2CQDWIwkAezc5CWX9ZNg6DzQXKkU6Q2AXu0NgFcp+OffcPGVGcgZjft7Cgi37iAgL5toODbitWyyNapWutV6MCSS+TCQTgHXAjcAo4CYgWVUf8EWgJaHMJhJPxw9AynQnsWyc5gyBBYc5Q2BNL3MSS/WG/o6y2K3efpCxc7fwzYod5OQp/ZrX4fZucXRpXNPK2RtzjnyZSJapatv8sigiEgpM8eZKLhEZBLwMBAPvqeqzBfZXAD4A2gN7getVNVVEagFfAB2Bcap63xnOPQlorKqtioqjXCQST7k5kPaL01PZ8APsTXG212756xBY/falcjEtb+0+dIIPf9nKxwu2se9oNi3qVWVE9ziuaFOPCiHlY+jPmAvly0SyUFU7ichPwL3ALmChqjYu4rhgYAPQH0gHFgE3qOpajzb3AgmqereIDAeGqur1IhIBtAVaAa0KJhIRuRoY5h5riaQomSmwYTKs/wG2zXeGwCKiIH6gk1ga94YKlf0dZbE4cTKXr5dtZ+zcLWzIOEJUlQrc0qURN3VuSC1bFtiYQvkykdwBfImzVvv7QGXg76r6VhHHdQX+oaoD3dePAajqMx5tprht5otICE6SilI3KBFJAjp4JhIRqQz8ANwFjLdEco6O7YOUGU5i2Tgdsg46Q2BxPZ1Li5sOguoN/B2lz6kqczZmMnbuFmav30OFkCCGtq3Pbd3iuLhu2Z9HMuZ8+P2qLREZBgxS1Tvc17cAnQskhdVum3T39Sa3Tab7OonfJpKXcBbXWgZ8e7ZEIiJ34SQbGjZs2H7r1q2+/5ClXe5Jp4ey/gcnsezb7Gyv0/rXIbDotmVuCCxl92HGzk09bVng27vHcWl8lJVhMcaDL3skfz/TdlUdVcRx1wIDCySSTqp6v0ebNW4bz0TSSVX3uq+T8Egk7loo/1TVK0UklkISiSfrkXhB1antlT8ElvaLs9BWRG1oOsBJKhf1hrCycxVU/rLAH8xPJeNQFhdFRXCblbM35hRvE4k3RYuOejwPB64Akr04Lh3wHCOJAXacpU26O7RVDdhXyDm7Au1FJBUn9toiMltVe3kRjymMCEQ1dR7dHnCGwDZOcxLL2kmw7CMIqQh9/w5d7ikTa6XUiAjjj72bcGePxkxevZMxP2/hb1+v5vmp67mxU0N+3zWWutXK3gJjxvjaOQ9tuVdaTcqf+yikXQjOZHtfYDvOZPuNqrrGo80fgdYek+1Xq+p1HvuTKDC05bEvFuuRlIzck859Kr+84VwFdvFguOp1qFTT35H5lKqyeOt+xszZwtS1uwgS4fIEpwxLQoyVYTHlT7HNkYhIDZyrtuK9aDsYGI1z+e9YVX1aREYBi1V1knuz44c4V2jtA4ar6mb32FSgKhAGHAAGFLjiKxZLJCVLFRa8DVP/BpXrwLCx0LCzv6MqFmn7jjFuXiqfL0rjSFYOHWOdMiwDWtYl2OZRTDnhyzmSVUB+o2AgCmfN9tcuOMoSYonEx7YvhS9ugwNp0PcJuOSBMjchn+/wiZNMWJzO+/O2kLbvODE1nDIs13dsQJVwK8NiyjZfJpJGHi9zgAxVzbnA+EqUJZJicOIgTBoJa7+Gi/o6a8xXjvJ3VMUmN0+ZtjaDsXO3sHDLPipXCOGadvW5qm192jaobnfNmzLJl4mk0IFwVS1scjwgWCIpJqqw5H2Y/ChUrAHDxjglWcq4VelOGZbvVu0kOyePBjUrcmVCNFe2iaZZ3SqWVEyZ4ctEkopzZdV+QIDqwDZ3txZ1h3sgsERSzHatgglJzn0olz4KPf9cLioQHzpxkqlrMvhmxQ5+TskkN0+Jr12ZIW2cpBIbWXYulTblky8TyVs4V2l9776+DOinqn/ySaQlwBJJCcg6At89DCs/d+6Sv/pdqFLX31GVmL1Hsvh+9S6+WbGDhVucTnpCTDWGtInmioRou4zYlEq+TCRLVLV9gW2LvTl5oLBEUkJUYfnH8N2fndpdV7/jlLIvZ3YePM63K3YyacUOVm0/iAh0iq3JlW2iGdy6HjUjyt+SyaZ08mUimQLMAT7CuXrrZqBnUfeRBBJLJCVs9zpnqGvPOujxMPR6HIK9ufe17Nm85wjfrnSSSsruI4QECd3jIxnSJpr+LerYlV8moPl6sv1JoKe76Uecy38DfpI9nyUSP8g+Bj/8BZZ+AA27wjVjoFp9f0flN6pK8s7DTFqxg29W7GD7geNUCAmiT7PaDGkTTe9mtQkPLfvzSqZ0KZYbEt3S8BGqeuhCgitplkj8aOUE+PZBp8Lw0LecNebLOVVl6bYDfLNiB9+u3EnmkSwqVwhhQIs6XJkYTfcmkYTa2vMmAPiyR/IJcDeQCyzBqYf1oqo+54tAS4IlEj/LTIEvkpyru7reB32fhBCbJwDIyc3jl837+GbFDiav3smhEznUqBTK4Nb1uLJNNJ1ia1pFYuM3vkwky1U1UURuwlnJ8C/AElVN8E2oxc8SSQA4eQKm/hUWvQf1OzjlVWo0Kvq4ciQrJ5efNmTyzYodTFubwfGTudStGs4VCfUYkhhN6/rV7B4VU6J8mUjWAInAJ8BrqvqjiKxQ1Ta+CbX4WSIJIGu+hkn3AwJXvQYthvg7ooB0LDuH6cm7mbR8Bz9u2M3JXCW2ViWubBPNkDbRxNexxbhM8fNlIhmJ0wtZAVwONAQ+UtUevgi0JFgiCTD7tsAXt8OOpdDpLhjwLwixZW/P5uCxk0xZs4tJK3Ywb1MmeQrN6lY5lVQa1Kzk7xBNGVWc1X8FCC5N9bYskQSgnGyY8RTMfw3qtYFh70Oti/wdVcDbffgE36/cyTcrd7Jk637AuUclqVssA1rUIcQm6Y0P+X2p3UBiiSSArZ8ME++GvFy4cjS0HubviEqNtH3H+GblDj5duI20fceJrhbOLV1jGd6xATXspkfjA5ZIPFgiCXAH0uDLEZC2ANonwaBnIbSiv6MqNXLzlBnJGYybl8q8TXsJDw1iaNv63HpJLM3qVvV3eKYUs0TiwRJJKZB7EmY9DT+/BLVbwLXjIOpif0dV6qzfdZhx87bw1dLtZOXkcclFtUi6JJa+zevYglzmnPk0kYjIJUAsHmu8q+oHFxJgSbJEUoqkTIev/gAnj8HlL0Dijf6OqFTafzSbzxal8eH8VHYcPEGDmhW5tWss13ZoQLWKVpbFeMeXV219CFwELMe5KRGc8vEjLzjKEmKJpJQ5tBO+uhNS50CbG2Dw804RSHPOcnLzmLo2g3FzU1mYuo9KYcFc0y6GWy+JpUlt+5qawvkykSQDLbQUj4FZIimF8nLhx/8HP/4HIuOdoa46Lf0dVam2evtBxs1LZdLyHWTn5tEjPpLbu8VxadMou3venJEvE8kEYKSq7vRVcCXNEkkptvlHp3dy4iBc9h9odyvY3d0XJPNIFp8u2MaHv2xl9+EsYmtV4tZLYhnWPsaqEZvT+DKRzMK5s30hkJW/XVVLzS3JlkhKuSN7YOJdsGkmtLoGrhgN4XY10oXKzsnjhzW7eH/uFpZtO0DlCiEMax9D0iWxtrqjAXybSC4903ZV/fE8YytxlkjKgLw8mDsaZv4LIiKhVjyEV4OK1SG8uvtvNY/nBbaF2gqFhVmedoBx7jr0OXlK74trk3RJLD3iI62+Vzlml/96sERShmz7Bea/Dsf2OsNdxw/AiQOQfaTw40LCvUs4+ds8k1RYRLkZTtt96AQfLdjGJwu2knkkmya1K3PrJbFc064+lcLK5+Jk5ZkveyRdgFeB5kAYEAwcVdVSM7ZgiaQcyD3pJJZTyWW/++9BJ9HkJxzP5HNq2yGcxT/PIijkt8mlYnWoFuMsJdywa5mrFZaVk8t3K3fy/txUVm0/SNXwEK7v2IDfd4212l7liC8TyWJgODAB6AD8HohX1cd9EWhJsERiCpWXB1mHPJJLgeRztoR0YBvkZkNoBMT1hPh+0KR/mSqP7yzCtZ+xc1P5YfUuVJV+zeuQ1C2Wro1r2bBXGedtIvGqr6qqKSISrKq5wPsiMu+CIzQmUAQFOT2MitWhxjkcl30UtsxxbqJMmQYbJjvba8VDfH9o0g8adSvV8zMiQvtGNWnfqCY7Dx7nw/lb+XThNqauzaBZ3SokXRLL79rWt2WCyzlveiQ/Af2A94BdwE4gydYjMcaDKuzd5CSUjdMg9WfIzYKQihDXw+mpxPeDmo39HekFO3Eyl0nLdzB27hbW7TpM9Uqh3NCpIUmXxFKnaulNmua3fDm01QjIwJkfeQhnqd03VDXFF4GWBEskpsRlH4Otc52kkjIN9m12ttds7CaV/hDbvVQXp1RVFmzZx/tztzBtbQahwUHc0qURd/e6iMjKZWvOqLzyda2tikBDVV3vi+BKmiUS43d7N0HKDCepbJkDOcedK8kadXOHwfo767GU0jmHrXuP8sqMFCYuSyc8NJjbusVyZ4/GVK9k5exLM1/2SK4EngfCVDVORBKBUXZDojHn6eRxt7cy3Zlf2bvR2V4j1plXadLfGQ4LK303BabsPsLLMzbyzYodVKkQwh09GnN791i7Y76U8mUiWQL0AWaralt320pVTfBJpCXAEokJaPu2uBP202HLT07l4+Awp7fSpJ/TY4lsWqp6K8k7D/HStA1MXZtB9Uqh/KHnRdx6SSO7F6WU8WUiWaCqnUVk2bkmEhEZBLyMc+/Je6r6bIH9FYAPgPbAXuB6VU0VkVrAF0BHYJyq3ue2r4RzGfJFOJWIv1HVR4uKwxKJKTVysmDrPCepbJwGme5ocrWG7uXF/SDu0lJTDXll+gFenLaB2ev3EFk5jHt7NeHGzg3tKq9SwpeJZAwwA3gUuAYYCYSq6t1FHBcMbAD6A+nAIuAGVV3r0eZeIEFV7xaR4cBQVb1eRCKAtkAroFWBRNJZVWeJSJgb179VdXJhsVgiMaXWgW1uUpkOW3507uAPCoVGXX8dBqvdPOB7K4tT9/HC1A3M37yXulXDub9vE65t34CwEFtjPpD5MpFUAv4KDAAEmAL8U1VPFHFcV+AfqjrQff0YgKo+49FmittmvoiE4FxeHJVfsl5EkoAO+YnkDO/xMrBaVd8tLBZLJKZMyMmGbfN/HQbb7f5NVrsl9PuHMwQW4AllXkomz09dz9JtB2hQsyIj+8QztG19QoItoQQiv9faEpFhwCBVvcN9fQtOb+I+jzar3Tbp7utNbptM93USZ0kkIlIdWAr0U9XNZ9h/F3AXQMOGDdtv3brVx5/QGD87mA4bpsC8V2H/FojtAf2fgvrt/R1ZoVSV2Rv28MLU9azefojGkRE82L8pV7SuZ+uiBBhvE0mRfwaISAcR+UpElorIyvyHNzGcYVvBrOVNmzPFFAJ8CrxypiQCoKrvqGoHVe0QFRVVZLDGlDrVYqDjCPjjQrjsOdidDO/2gQlJv963EoBEhN4X1+ab+7rz9i3tCQ0OYuSny7js5TlMWeOUYTGlizeXUHwMPAKsAvLO4dzpQAOP1zHAjrO0SXeTQzVgnxfnfgfYqKqjzyEeY8qmkDDofBe0Ge70Tua/BsnfQIfboef/QeXA/ENKRBjYsi79m9fh21U7GT1tA3/4cAmt61fj4QFN6dU0ymp5lRLeDEzuUdVJqrpFVbfmP7w4bhEQLyJx7sT4cGBSgTaTgFvd58OAmUUt6Ssi/8JJOA96EYMx5Ud4VejzVxi5DNreDIvGwCtt4cfnnLpgASooSBjSJpqpD/XkuWEJ7D+WzW3vL2LYW/OZtynT3+EZL3gz2d4XuAHnCinPFRK/KvLkIoOB0TiX/45V1adFZBSwWFUniUg48CHOFVr7gOH5Q1UikgpUxSnNcgBnsv8QkAas84jlNVV9r7A4bLLdlEt7NsCMp2Ddt1C5LvR6FNreAsGBfS9Hdk4eE5ak8eqMFHYdOkHXxrX488CmtG9U09+hlTu+vGrrI6AZsIZfh7ZUVW+/4ChLiCUSU65t+wWm/R3SFjg3NvZ9EppdHvBXeJ04mcsnC7bxxuwUMo9k0+viKP7U/2Jax1Tzd2jlhi8TySpVbe2zyPzAEokp91Rh3Xcw/R9OSZYGXaD/KGjY2d+RFelYdg4fzN/KWz9u4sCxkwxsWYeH+jelWd1Ss7ZeqeXLRPIu8JLnjYSljSUSY1y5ObDsQ5j9DBzJgGZXOD2UqKb+jqxIh0+cZOzPqbw3ZzNHsnO4IiGaB/vFc1FU6bjLvzTyZSJJxilJsgVnXkJwhras1pYxpVX2UZj/Bswd7RSRbHcL9HoMqtT1d2RFOnAsm3fnbOb9uamcOJnL1e1ieKBvvC0BXAx8vR7Jb3h55VZAsERizFkc2QM/PQeLxziFIrveB91GQoUq/o6sSJlHsnhr9iY+/GUruXnK9R0bcF+fJtSrVnrXeAk0fr+zPZBYIjGmCPs2w4x/wpqvoFIkXPoXaJ/k3KMS4DIOneD1WSl8unAbIsKtXRvxx95NbC0UH7BE4sESiTFe2r4Epj0JqXOgRhz0/Tu0HBrwV3gBpO8/xujpG/lyaTpVw0O5r3cTbunayCoNXwBLJB4skRhzDlSdEvbTn3QKQ0a3c67wiuvh78i8krzzEP/5YR2z1++hfvWKPDLwYoa0ibY6XufBEokHSyTGnIe8XFjxGcx6Gg5th/iBTpXhOi38HZlX5qZk8szkZFZvP0TL6Ko8Prg53ZpE+jusUsUSiQdLJMZcgJPHYcHbMOdFyD4MbW6E3o9Dtfr+jqxIeXnKpBU7eG7KerYfOM6lTaN4bHAzuwfFS5ZIPFgiMcYHju2DOS/AwndAgqDz3dD9IahY3d+RFenEyVw+nL+VV2du5HBWDsPaxfDwgKZ2hVcRLJF4sERijA8d2AYzn4aVnztJpMefodOdEFLB35EV6cCxbN6YvYlxc1MRgRHd47i710VUDQ/1d2gByRKJB0skxhSDnSudkiubZjhrynf9I7S6JmDL1ntK23eMF6au5+vlO6hRKZSRfeO5qXMjW/q3AEskHiyRGFOMNs+GGaOcS4clGC7qDa2vcwpDVgjs8iWrtx/k398nM2/TXhrVqsT/DWzG4NZ1bR0UlyUSD5ZIjCkBGWth1XhY9QUcTIPQSk4yaX2dk1yCA3P4SFX5ccMenp28jnW7DtOmQXX+Org5neKsbL0lEg+WSIwpQXl5kPYLrBwPaybCiQNQqRa0vBoSroOYjgF5g2NunvLl0nRenLqBXYdO0K95HR697GKa1A78cjHFxRKJB0skxvhJTjakTHOSyoYfIOcE1Ih1eikJ10FkvL8j/I3j2bmMnbuFN2dv4lh2Dtd3bMhD/eOpXSXc36GVOEskHiyRGBMAThxy1pJfNR62/ASaB/USnYTS6pqAqzy890gWr85M4aNfthIWEsSdPRpzV8/GRFQI7BUmfckSiQdLJMYEmEM7YfWXTlLZucK5LyXuUiepNLvCWX8+QKRmHuW5Kev5btVOIitX4MF+8VzfsQGhwWX/Ci9LJB4skRgTwPash1UTnOGvA1shJBwuvswZ/mrSL2AqEC/btp9/f5/MotT9NI6K4C+DmjGgRZ0yfYWXJRIPlkiMKQVUIW2h00tZ/RUc3wcVa0CL30HC9dCgMwT5txegqkxP3s2zk5PZtOcoHWNr8Njg5rRrWMOvcRUXSyQeLJEYU8rknoRNM51eyrrvIOe4c9Nj62HO8Fft5n4NLyc3j/GL03lx2gYyj2QxuHVdHhnYjLjICL/G5WuWSDxYIjGmFMs67CSTleNh8yxnkr5ua2foq/UwqBrtt9COZuXw7pzNvPPTZrJz8ripc0NG9o2nVuXALxfjDUskHiyRGFNGHNntDHutGu/cSY9AbHenl9J8iN8KSO4+fIKXp2/ks0VpVAwN5q6ejbmmfQz1q5fuopCWSDxYIjGmDNq7yemlrBrvLBUcXAGaDoB2t8JFff0yn5Ky+wj/+WEd09ZmANAyuir9mtehf4s6tIyuWuom5i2ReLBEYkwZpgrbl/5anuVYpnPTY/vboO0tEFGrxEPatOcI09dmMD05gyVb95OnUK9aOP2a16Ffizp0aVyTCiGBvwSwJRIPlkiMKSdysiF5EiweC1vnOr2Ulr+Djnf4rTTL3iNZzFy3m+nJGfy0IZPjJ3OJCAvm0ouj6Ne8Dn2a1aZ6pcC4xLkgSyQeLJEYUw5lrHUSyorPnJUd67SGjiOg9bV+q0p84mQu8zftZVpyBtPXZrD7cBbBQUKHRjXo36IO/ZrXITaArvyyROLBEokx5VjWEWfYa9EYyFgNFapCm+HQYQTUbua3sPLylFXbDzI9OYNpazNYt+swAE1qVz6VVBIbVCc4yH/zKpZIPFgiMcacuuFx8RinKnFuNjTqDh1vh2ZX+v0O+rR9x5ie7MyrLNi8j5w8JbJyGH2a1aZf8zr0iI+iYljJzqtYIvFgicQYc5qjmbDsI2fo68BWiKgN7X4P7ZOgegN/R8fB4yf5ccMepq/NYNb63Rw+kUOFkCB6xEc68yrNa5dINWJLJB4skRhjzigvz1kqeNF7sGGKMxnfdJAzl9K4j99LsgBk5+SxKHUf09Y6Q2DbDxxHBBIbVD91aXF87crFcmlxQCQSERkEvAwEA++p6rMF9lcAPgDaA3uB61U1VURqAV8AHYFxqnqfxzHtgXFAReB74AEt4kNYIjHGFGn/VlgyDpZ9CEf3QI046HA7tL0ZKgXGaomqyvqMw0xb4wyBrUg/CEDDmpVOJZWOsTUI8VFlYr8nEhEJBjYA/YF0YBFwg6qu9WhzL5CgqneLyHBgqKpeLyIRQFugFdCqQCJZCDwA/IKTSF5R1cmFxWKJxBjjtfxLiBeNgW3z3EuIh7qXEHcIqNUdMw6dYEayc2nxzymZZOfkUa1iKL0vjqJfizpc2jSKKuHnv8RxICSSrsA/VHWg+/oxAFV9xqPNFLfNfBEJAXYBUfk9DBFJAjrkJxIRqQfMUtVm7usbgF6q+ofCYrFEYow5Lxlrncn5FZ87lxDXTfj1EuKwwLlMF5y6X3M2ZjI9OYOZ63az72g2ocHC/Mf6Enmetb+8TSTFudRXfSDN43U60PlsbVQ1R0QOArWAzELOmV7gnPXP1HAVGmMAAAb5SURBVFBE7gLuAmjYsOG5xm6MMVCnBVz+AvT7h1OOZfFY+OYBmPoEtLnBSSpRF/s7SgAiKoQwqFVdBrWqS27e/2/vbmPkquo4jn9/3e1uurt9kIAkdoEtiAISoNiYSsUYawhGIryosSCVYHxDQB5iomI0JrzxDRiNIdoGSlAaNdaSNAaBWEyVRPq0LWApJA1Cu7SGJtaWNdIn/r44ZzOzm+lu3evtGTq/TzLpzsm9t/852dnfnHvPnBts33OQ4T0Hpx0i/4s6g6TV+G/i8OdUtpnW9hGxClgFaUQyyTHNzCbXOzuFxqKvwd5N6bTXtsdg80oYuja1X3JD8SnEY7pmiEVDZ7Fo6PRc26kzSEaA5nl0g8C+k2wzkk9tzQX+OcUxB6c4pplZPSQ4f3F6XP/DdGF+62pYezsMnNuYQjx3cMpDnUnqDJItwMWSFgBvAcuBWyZssx64DfgrsAx4brIZWBGxX9I7khYDm4CvAj+to3gzs0n1nw2fug+uuRt2b0jXUv78IPzlobT68Lzz00imdyB9m753NvQM5LY5uX12eszsb4upxtNVW5Dkax53Ac+Qpv+ujoidkh4AtkbEeuBR4JeSdpNGIsvH9pf0BjAH6JF0E3BdnvF1B43pv3/IDzOzMmZ0peXrP3JdYwrxrvWwbxjePQzvHTuFg6gpZJoCpqcphMbaW7X1zmnsP3PWaZ9Z5i8kmpnV6fiRtN7XkcPpbo9HR9O/Ex9Hm7Y5MtqifRTixNT/n7rGj4K+vgF6+qZVejvM2jIzs+7e9Kh6X5QIOPafSULn8ISQytt017+UioPEzOz9QEoji54+4NzS1Yzz/r26Y2ZmbcFBYmZmlThIzMysEgeJmZlV4iAxM7NKHCRmZlaJg8TMzCpxkJiZWSUdsUSKpAPAm9Pc/WxOfn+UTuT+aHBfjOf+aDhT+uKCiDhnqo06IkiqkLT1VNaa6RTujwb3xXjuj4ZO6wuf2jIzs0ocJGZmVomDZGqrShfQZtwfDe6L8dwfDR3VF75GYmZmlXhEYmZmlThIzMysEgfJSUi6XtJrknZL+k7pekqSdJ6kP0naJWmnpHtK19QOJHVJ2i7p96VrKUnSPElrJb2af0c+WbqmkiTdl98nf5P0K0n136KwMAdJC5K6gIeBzwOXATdLuqxsVUUdB74ZEZcCi4E7O7w/xtwD7CpdRBv4CfB0RFwCXEkH94mk+cDdwKKIuBzoApaXrap+DpLWPgHsjojXI+Io8GvgxsI1FRMR+yNiOP/8DukPxfyyVZUlaRD4AvBI6VpKkjQH+DTwKEBEHI2If5WtqrhuYJakbqAP2Fe4nto5SFqbD+xtej5Ch//hHCNpCFgIbCpbSXE/Br4FvFe6kMIuBA4Aj+XTfI9I6i9dVCkR8RbwILAH2A8ciohny1ZVPwdJa2rR1vHzpCUNAL8D7o2Iw6XrKUXSDcDbEbGtdC1toBu4GvhZRCwE/g107DVFSR8gnb1YAHwI6Jd0a9mq6ucgaW0EOK/p+SAdMDydjKSZpBBZExHrStdT2BLgi5LeIJ32/KykJ8qWVMwIMBIRYyPUtaRg6VSfA/4eEQci4hiwDrimcE21c5C0tgW4WNICST2ki2XrC9dUjCSRzoHviogfla6ntIi4PyIGI2KI9LvxXESc8Z86W4mIfwB7JX00Ny0FXilYUml7gMWS+vL7ZikdMPmgu3QB7Sgijku6C3iGNOtidUTsLFxWSUuAFcDLknbktu9GxFMFa7L28Q1gTf7Q9Tpwe+F6iomITZLWAsOk2Y7b6YDlUrxEipmZVeJTW2ZmVomDxMzMKnGQmJlZJQ4SMzOrxEFiZmaVOEjM2pikz3T66sLW/hwkZmZWiYPE7P9A0q2SNkvaIWllvlfJqKSHJA1L2iDpnLztVZJekPSSpCfz+kxI+rCkP0p6Me9zUT78QNP9Ptbkb0ybtQ0HiVlFki4FvgwsiYirgBPAV4B+YDgirgY2Aj/Iu/wC+HZEXAG83NS+Bng4Iq4krc+0P7cvBO4l3RvnQtJKA2Ztw0ukmFW3FPg4sCUPFmYBb5OWmP9N3uYJYJ2kucC8iNiY2x8HfitpNjA/Ip4EiIh3AfLxNkfESH6+AxgCnq//ZZmdGgeJWXUCHo+I+8c1St+fsN1k6xFNdrrqSNPPJ/D71tqMT22ZVbcBWCbpgwCSzpJ0Aen9tSxvcwvwfEQcAg5Kuja3rwA25vu7jEi6KR+jV1LfaX0VZtPkTzZmFUXEK5K+BzwraQZwDLiTdJOnj0naBhwiXUcBuA34eQ6K5tVyVwArJT2Qj/Gl0/gyzKbNq/+a1UTSaEQMlK7DrG4+tWVmZpV4RGJmZpV4RGJmZpU4SMzMrBIHiZmZVeIgMTOzShwkZmZWyX8B7BJ3I1YewmIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# history_object = model.fit_generator(train_generator, samples_per_epoch =\n",
    "#     len(train_samples), validation_data = \n",
    "#     validation_generator,\n",
    "#     nb_val_samples = len(validation_samples), \n",
    "#     nb_epoch=5, verbose=1)\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
